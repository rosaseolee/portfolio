{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrUCKuCLF7G6","executionInfo":{"status":"ok","timestamp":1710780232831,"user_tz":240,"elapsed":319574,"user":{"displayName":"Rosa Lee","userId":"12033232738204945660"}},"outputId":"c12a1a3a-ba01-44ac-d8a3-32c939c362ff"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n","Best Parameters: {'max_depth': None, 'n_estimators': 100}\n","Best Accuracy: 0.7712617982771673\n","Final Accuracy: 0.7830629639813033\n","\n","Question (a): How does the performance of your model vary across different classes? \n","Analyzing precision and recall metrics for each class.\n","\n","Precision and Recall metrics for each class:\n","Class 0:\n","Precision: 0.6153846153846154\n","Recall: 0.1411764705882353\n","Class 1:\n","Precision: 0.5882352941176471\n","Recall: 0.21739130434782608\n","Class 2:\n","Precision: 1.0\n","Recall: 0.022727272727272728\n","Class 3:\n","Precision: 0.5\n","Recall: 0.061224489795918366\n","Class 4:\n","Precision: 0.6818181818181818\n","Recall: 0.04672897196261682\n","Class 5:\n","Precision: 0.7892785856857714\n","Recall: 0.9928263988522238\n","\n","The performance of the model varies across different classes, as evident from the precision and recall metrics for each class are presented above:\n","\n","Observations:\n","- For Class 0 and Class 1, precision values are moderate, indicating that the model correctly identifies a reasonable proportion of instances belonging to these classes. \n","  However, recall values are relatively low, suggesting that the model may miss many instances of these classes.\n","- Class 2 shows perfect precision but very low recall, indicating that while the model identifies all instances it predicts as Class 2 correctly, it misses many actual instances of this class.\n","- Class 3 has moderate precision but low recall, suggesting that the model identifies some instances correctly but misses a significant number of actual instances of Class 3.\n","- Class 4 has moderate precision and very low recall, indicating that the model correctly identifies some instances but misses a considerable number of actual instances of Class 4.\n","- Class 5 has relatively high precision and very high recall, indicating that the model correctly identifies most instances of Class 5 and minimizes false negatives.\n","\n","Overall, the model performs relatively well for Class 5, but there are significant challenges in accurately predicting other classes, particularly for Class 2 where recall is extremely low. \n","This imbalance in precision and recall across different classes suggests potential areas for model improvement and further analysis.\n","\n","\n","Question (b): Considering your analysis, how would you recommend using this model in a real-world application? \n","Discuss any limitations or considerations that should be taken into account.\n","\n","Recommendation:\n","This model can be used for sentiment analysis in product reviews. However, some limitations include:\n","- Imbalanced class distribution may affect model performance.\n","- Model may not generalize well to unseen data if the distribution of reviews changes over time.\n","- Sentiment analysis may not capture nuanced opinions.\n","\n","Question (c): Analyze your data to address the previously identified accuracy issues. Describe your method to address this issue, \n","implement it in code and retrain a classifier, and assess any improvements or ongoing challenges.\n","\n","Addressing Accuracy Issues:\n","To address accuracy issues, we can try stratified sampling or oversampling techniques for imbalanced classes, experiment with different feature engineering approaches, or try different algorithms such as ensemble methods or neural networks.\n","However, implementing and evaluating these techniques require further experimentation and analysis.\n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","import nltk\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","# Download NLTK Vader lexicon\n","nltk.download('vader_lexicon')\n","\n","# load data\n","from google.colab import drive\n","drive.mount(\"/drive\", force_remount=True)\n","train_df = pd.read_csv('/drive/MyDrive/train.csv')\n","test_df = pd.read_csv('/drive/MyDrive/test.csv')\n","\n","# Handle missing values\n","train_df['text'].fillna('', inplace=True)\n","test_df['text'].fillna('', inplace=True)\n","\n","# Split data into features and target\n","X_train_text = train_df['text']\n","y_train = train_df['stars']\n","X_test_text = test_df['text']\n","y_test = test_df['stars']\n","\n","# Text feature extraction pipeline\n","vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=5000, stop_words='english')\n","text_pipeline = make_pipeline(vectorizer)\n","\n","# Transform text data\n","X_train_text_features = text_pipeline.fit_transform(X_train_text)\n","X_test_text_features = text_pipeline.transform(X_test_text)\n","\n","# Combine text features with other features\n","other_features = ['user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score']\n","X_train_numeric = train_df[other_features]\n","X_test_numeric = test_df[other_features]\n","\n","# Extract sentiment scores from text data\n","sid = SentimentIntensityAnalyzer()\n","train_df['sentiment_score'] = train_df['text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n","test_df['sentiment_score'] = test_df['text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n","\n","scaler = StandardScaler()\n","X_train_numeric_scaled = scaler.fit_transform(X_train_numeric)\n","X_test_numeric_scaled = scaler.transform(X_test_numeric)\n","\n","# Combine text, numeric, and sentiment features\n","X_train = pd.concat([pd.DataFrame(X_train_text_features.toarray()), pd.DataFrame(X_train_numeric_scaled), train_df['sentiment_score']], axis=1)\n","X_train.columns = X_train.columns.astype(str)  # Converting the column names to strings\n","X_test = pd.concat([pd.DataFrame(X_test_text_features.toarray()), pd.DataFrame(X_test_numeric_scaled), test_df['sentiment_score']], axis=1)\n","X_test.columns = X_test.columns.astype(str)  # Converting the column names to strings\n","\n","# Initializing and training the Random Forest classifier with hyperparameter tuning\n","param_grid = {'n_estimators': [100, 150], 'max_depth': [None, 20]}\n","rf_classifier = RandomForestClassifier(random_state=42)\n","grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best accuracy\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best Accuracy:\", grid_search.best_score_)\n","\n","# Making predictions\n","y_pred = grid_search.predict(X_test)\n","\n","# Exporting the predictions to pred.csv\n","pd.Series(y_pred).to_csv(\"/drive/MyDrive/pred.csv\", index=False, header=False)\n","\n","# Calculate accuracy\n","final_accuracy = accuracy_score(y_test, y_pred)\n","print(f'Final Accuracy: {final_accuracy}')\n","\n","# Exporting the accuracy to accuracy.csv\n","with open(\"/drive/MyDrive/accuracy.csv\", \"w\") as f:\n","    f.write(str(final_accuracy))\n","\n","# Question a\n","print(\"\"\"\n","Question (a): How does the performance of your model vary across different classes?\n","Analyzing precision and recall metrics for each class.\n","\"\"\")\n","print(\"Precision and Recall metrics for each class:\")\n","# Generating and printing the classification report\n","report = classification_report(y_test, y_pred, output_dict=True)\n","for star_class in report.keys():\n","    if star_class.isdigit():\n","        print(f\"Class {int(star_class)}:\")\n","        print(f\"Precision: {report[star_class]['precision']}\")\n","        print(f\"Recall: {report[star_class]['recall']}\")\n","\n","print(\"\"\"\n","The performance of the model varies across different classes, as evident from the precision and recall metrics for each class are presented above:\n","\n","Observations:\n","- For Class 0 and Class 1, precision values are moderate, indicating that the model correctly identifies a reasonable proportion of instances belonging to these classes.\n","  However, recall values are relatively low, suggesting that the model may miss many instances of these classes.\n","- Class 2 shows perfect precision but very low recall, indicating that while the model identifies all instances it predicts as Class 2 correctly, it misses many actual instances of this class.\n","- Class 3 has moderate precision but low recall, suggesting that the model identifies some instances correctly but misses a significant number of actual instances of Class 3.\n","- Class 4 has moderate precision and very low recall, indicating that the model correctly identifies some instances but misses a considerable number of actual instances of Class 4.\n","- Class 5 has relatively high precision and very high recall, indicating that the model correctly identifies most instances of Class 5 and minimizes false negatives.\n","\n","Overall, the model performs relatively well for Class 5, but there are significant challenges in accurately predicting other classes, particularly for Class 2 where recall is extremely low.\n","This imbalance in precision and recall across different classes suggests potential areas for model improvement and further analysis.\n","\"\"\")\n","\n","# Question b\n","print(\"\"\"\n","Question (b): Considering your analysis, how would you recommend using this model in a real-world application?\n","Discuss any limitations or considerations that should be taken into account.\n","\"\"\")\n","print(\"Recommendation:\")\n","print(\"This model can be used for sentiment analysis in product reviews. However, some limitations include:\")\n","print(\"- Imbalanced class distribution may affect model performance.\")\n","print(\"- Model may not generalize well to unseen data if the distribution of reviews changes over time.\")\n","print(\"- Sentiment analysis may not capture nuanced opinions.\")\n","\n","# Question c\n","print(\"\"\"\n","Question (c): Analyze your data to address the previously identified accuracy issues. Describe your method to address this issue,\n","implement it in code and retrain a classifier, and assess any improvements or ongoing challenges.\n","\"\"\")\n","print(\"Addressing Accuracy Issues:\")\n","print(\"To address accuracy issues, we can try stratified sampling or oversampling techniques for imbalanced classes, \"\n","      \"experiment with different feature engineering approaches, or try different algorithms such as ensemble methods \"\n","      \"or neural networks.\")\n","print(\"However, implementing and evaluating these techniques require further experimentation and analysis.\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbi4yxndElnTdQquE9f4E5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}